{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1470963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing LLM classifyer with ROAR Section B \n",
    "\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import PromptLayerChatOpenAI\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain, StuffDocumentsChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "import promptlayer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "gpt_model = \"gpt-4\"\n",
    "\n",
    "\n",
    "openai_api_key = \"Key\"\n",
    "promptlayer_api_key= \"Key\"\n",
    "\n",
    "\n",
    "# Set the PromptLayer API key\n",
    "promptlayer.api_key = promptlayer_api_key\n",
    "\n",
    "# Assuming 'promptlayer.openai' is the correct way to access the OpenAI configuration within promptlayer,\n",
    "# set the OpenAI API key\n",
    "promptlayer.openai.api_key = openai_api_key\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1fda133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "#Select the csv filename for modelling\n",
    "filename = \"test.csv\"\n",
    "topic_filename = \"Topic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3217a8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data \n",
    "df = pd.read_csv(filename)\n",
    "captions = df['Caption'].iloc[1:]\n",
    "doc_captions = [Document(page_content=t) for t in captions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4b4ad3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics List: Geopolitical tensions\n",
      "\n",
      "Covid\n",
      "\n",
      "diseases\n",
      "\n",
      "Low economic diversification\n",
      "\n",
      "environmental deterioration\n",
      "\n",
      "disaster\n",
      "\n",
      "poverty\n",
      "\n",
      "political instability\n",
      "\n",
      "deterioration of the security situation\n",
      "\n",
      "pandemic\n",
      "\n",
      "Lack of funding\n",
      "\n",
      "Inflation\n",
      "\n",
      "volatile economic growth.\n",
      "\n",
      "Gender Based Violene\n",
      "\n",
      "Low human capacity\n"
     ]
    }
   ],
   "source": [
    "# Read Existing Topics from CSV\n",
    "df = pd.read_csv(topic_filename)\n",
    "existing_topics = df[\"topics\"]\n",
    "\n",
    "if len(existing_topics)!=1:\n",
    "    topics_combined = '\\n\\n'.join(existing_topics.astype(str))\n",
    "else:\n",
    "    topics_combined = ''\n",
    "    \n",
    "print(f\"Topics List: {topics_combined}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d15d2e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map Prompt\n",
    "\n",
    "llm = PromptLayerChatOpenAI(model=gpt_model, pl_tags=[\"Classifier\"], openai_api_key=\"Key\")\n",
    "map_template = \"\"\" Prompt\n",
    "\"\"\"\n",
    "\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm,prompt=map_prompt)\n",
    "\n",
    "\n",
    "# Function to extract challenges\n",
    "def extract_challenges(output):\n",
    "    if 'challenges' in output:\n",
    "        return output['challenges']\n",
    "    elif 'text' in output:\n",
    "        challenges_text = output['text']\n",
    "        return challenges_text.split('\\n')\n",
    "    return []\n",
    "\n",
    "# Placeholder for DataFrame rows\n",
    "rows = []\n",
    "\n",
    "# Extracting text content from each Document\n",
    "captions = [doc.page_content for doc in doc_captions]\n",
    "\n",
    "# Process each caption individually\n",
    "for caption in captions:\n",
    "    # Adjust this line to correctly invoke your model for a single caption and capture the output\n",
    "    output = map_chain.invoke({\"captions\": caption})\n",
    "    \n",
    "    challenges = extract_challenges(output)\n",
    "    \n",
    "    # Add caption and its challenges to the rows list\n",
    "    row = [caption] + challenges\n",
    "    rows.append(row)\n",
    "\n",
    "# Determine the maximum number of columns needed\n",
    "max_cols = max(len(row) for row in rows)\n",
    "\n",
    "# Create column headers\n",
    "columns = ['Caption'] + [f'Challenge {i+1}' for i in range(1, max_cols)]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Fill any missing values with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "csv_filename = 'captions_and_individual_challenges.csv'\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f47f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce Prompt and Chain\n",
    "#The following prompt is for the \"reduce\" step of the algorithm. \n",
    "# It operates against the entire set of output that is produced by the \"map\" chain.\n",
    "#In our example, the map chain yields a set of topics that are defined on the caption it was run on. These are then grouped together and passed as a result to this reduce chain. This reduce chain is designed to take this global output of the map step and reduce it down to a final set of unique fertility topics that minimized contextual overlap.                                                                                                                                \n",
    "reduce_template = \"\"\"Prompt\n",
    "\"\"\"\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "reduce_prompt = PromptTemplate(template=reduce_template,input_variables=[\"topics\"],partial_variables={\"format_instructions\":format_instructions})\n",
    "#reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain=LLMChain(llm=llm,prompt=reduce_prompt)\n",
    "\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"topics\"\n",
    ")\n",
    "\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    token_max=4000)\n",
    "\n",
    "\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    document_variable_name=\"captions\",\n",
    "    return_intermediate_steps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af38760e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Run Map-Reduce Chain\n",
    "#in this step we run the actual MapReduceDocumentsChain, \n",
    "# this will then begin to process all of the captions that were read in from the CSV file and perform the\n",
    "# \"map\" step on each of them. Once the \"map\" step is completed opn all of them it will then run the final\n",
    "#\"reduce\" step and output a final list of topics.\n",
    "\n",
    "output = map_reduce_chain.invoke(doc_captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dcfcbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 31 new topics\n",
      "Political Instability\n",
      "Socio-economic Challenges\n",
      "Impacts of External Shocks\n",
      "Macroeconomic Degradation\n",
      "Limited Economic Growth\n",
      "Effects of Climate Change\n",
      "Difficulties in Resource Mobilization\n",
      "Security Concerns\n",
      "Governance Challenges\n",
      "Low Human Development Index\n",
      "Urban and Monetary Poverty\n",
      "Budget Deficit and Social Spending\n",
      "High Public Debt\n",
      "Inflation Control\n",
      "Access to International Financing and Global Demand Uncertainty\n",
      "GDP per Capita\n",
      "Human Capacity Development\n",
      "Environmental Challenges\n",
      "Internal Displacement and Humanitarian Needs\n",
      "Terrorism\n",
      "Democratic Process Absence\n",
      "Constitutional Revisions\n",
      "Financial Constraints\n",
      "Economic Diversification\n",
      "Market Downturns\n",
      "Private Sector Development\n",
      "Trade and Investment Opportunities\n",
      "Policy and Regulatory Framework Implementation\n",
      "Data and Evidence Availability\n",
      "Impact Assessments\n",
      "Application of Foresight.\n"
     ]
    }
   ],
   "source": [
    "# Printing out the New Topics and Inspect total number of topics\n",
    "text_to_parse = output['output_text']\n",
    "\n",
    "# Use the parsing method to split the string into a list of topics\n",
    "new_topics = text_to_parse.split(\", \")\n",
    "\n",
    "# Display the results\n",
    "print(f\"Generated {len(new_topics)} new topics\")\n",
    "for topic in new_topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dbcad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the following step, we use a new separate chain to eliminate any new topics which are already covered or similar to topics that were read in at the start of processing.\n",
    "\n",
    "eliminate_duplicates_template = \"\"\"Prompt\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(template=eliminate_duplicates_template, input_variables=[\"new_topics\",\"existing_topics\"],partial_variables={\"format_instructions\":format_instructions})\n",
    "llm_chain = LLMChain(llm=llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37c3138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model to merge duplicated topics and for summary\n",
    "\n",
    "prompt_template = PromptTemplate(template=eliminate_duplicates_template, input_variables=[\"new_topics\",\"existing_topics\"],partial_variables={\"format_instructions\":format_instructions})\n",
    "llm_chain = LLMChain(llm=llm,prompt=prompt_template)\n",
    "output2 = llm_chain.predict(new_topics=output,existing_topics=topics_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c17c911b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Socio-economic Challenges, Impacts of External Shocks, Macroeconomic Degradation, Limited Economic Growth, Difficulties in Resource Mobilization, Governance Challenges, Urban and Monetary Poverty, Budget Deficit and Social Spending, High Public Debt, Inflation Control, Access to International Financing and Global Demand Uncertainty, GDP per Capita, Human Capacity Development, Internal Displacement and Humanitarian Needs, Terrorism, Democratic Process Absence, Constitutional Revisions, Financial Constraints, Market Downturns, Private Sector Development, Trade and Investment Opportunities, Policy and Regulatory Framework Implementation, Data and Evidence Availability, Impact Assessments, Application of Foresight.`\n"
     ]
    }
   ],
   "source": [
    "# check output \n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "407ab151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated final set of 25 topics.\n",
      "['`Socio-economic Challenges', 'Impacts of External Shocks', 'Macroeconomic Degradation', 'Limited Economic Growth', 'Difficulties in Resource Mobilization', 'Governance Challenges', 'Urban and Monetary Poverty', 'Budget Deficit and Social Spending', 'High Public Debt', 'Inflation Control', 'Access to International Financing and Global Demand Uncertainty', 'GDP per Capita', 'Human Capacity Development', 'Internal Displacement and Humanitarian Needs', 'Terrorism', 'Democratic Process Absence', 'Constitutional Revisions', 'Financial Constraints', 'Market Downturns', 'Private Sector Development', 'Trade and Investment Opportunities', 'Policy and Regulatory Framework Implementation', 'Data and Evidence Availability', 'Impact Assessments', 'Application of Foresight.`']\n"
     ]
    }
   ],
   "source": [
    "# Print New Topics\n",
    "new_topics = output_parser.parse(output2)\n",
    "print(f\"Generated final set of {len(new_topics)} topics.\")\n",
    "print(new_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d906d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diseases', 'environmental deterioration', 'Difficulties in Resource Mobilization', 'deterioration of the security situation', 'Application of Foresight.`', 'Policy and Regulatory Framework Implementation', 'Market Downturns', 'Democratic Process Absence', 'volatile economic growth.', 'Low human capacity', 'Constitutional Revisions', 'Covid', 'Inflation', 'Financial Constraints', 'Budget Deficit and Social Spending', 'Gender Based Violene', 'poverty', 'political instability', 'Inflation Control', 'Low economic diversification', 'Private Sector Development', 'Human Capacity Development', 'Internal Displacement and Humanitarian Needs', 'Lack of funding', 'Trade and Investment Opportunities', 'Urban and Monetary Poverty', 'Terrorism', 'Macroeconomic Degradation', 'disaster', 'GDP per Capita', 'Governance Challenges', '`Socio-economic Challenges', 'Access to International Financing and Global Demand Uncertainty', 'High Public Debt', 'pandemic', 'Limited Economic Growth', 'Impact Assessments', 'Impacts of External Shocks', 'Data and Evidence Availability', 'Geopolitical tensions']\n"
     ]
    }
   ],
   "source": [
    "#Merge the existing topics list with the new set of topics\n",
    "existing_topics_lower = [item.lower() for item in existing_topics]\n",
    "new_topics_lower = [item.lower() for item in new_topics]\n",
    "\n",
    "merged_topics_list_lower = existing_topics_lower + new_topics_lower\n",
    "unique_topics_list_lower = list(set(merged_topics_list_lower))\n",
    "\n",
    "final_topics_list = []\n",
    "for item in unique_topics_list_lower:\n",
    "    if item in existing_topics_lower:\n",
    "        final_topics_list.append(existing_topics[existing_topics_lower.index(item)])\n",
    "    elif item in new_topics_lower:\n",
    "        final_topics_list.append(new_topics[new_topics_lower.index(item)])\n",
    "\n",
    "print(final_topics_list)\n",
    "\n",
    "df = pd.DataFrame({'topics':final_topics_list})\n",
    "df.to_csv(topic_filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b8421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
